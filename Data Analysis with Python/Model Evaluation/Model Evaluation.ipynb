{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f2c681",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "* In-sample evaluation tells us how well our model fits the data already given to train\n",
    "  it.\n",
    "\n",
    "\n",
    "**Problem?**\n",
    "\n",
    "* It does not give us an estimate of how well the trained model can predict new data.\n",
    "\n",
    "**Solution?**\n",
    "\n",
    "* The solution is to split our data up, use the In-sample data or training data to train\n",
    "  the model.\n",
    "  \n",
    "\t* In-sample data or training data\n",
    "    \n",
    "* The rest of the data called test data is used as out-of-sample data.\n",
    "\n",
    "\t* Out-o0f-sample evaluation or test set\n",
    "    \n",
    "This data is then used to approximate how the model performs in the real world.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de23d6d4",
   "metadata": {},
   "source": [
    "# Training / Testing Sets\n",
    "\n",
    "**Test Data**\n",
    "\n",
    "Separating data into training and testing sets is an important part of model evaluation.\n",
    "\n",
    "We use the test data to get an idea how our model will perform in the real world.\n",
    "\n",
    "When we split a data set, usually the larger portion of data is used for training and a\n",
    "smaller part is used for testing.\n",
    "\n",
    "\n",
    "* Split dataset into:\n",
    "\n",
    "\t* Training set (70%)\n",
    "    \n",
    "    \t* We use a training set to build a model and discover predictive relationships.\n",
    "    \n",
    "    * Testing set (30%)\n",
    "    \n",
    "    \t* We then use a testing set to evaluate model performance.\n",
    "    \n",
    "\n",
    "* Build and train the model with a training set\n",
    "\n",
    "* Use testing set to assess the performance of a predictive model\n",
    "\n",
    "* When we have completed testing our model, we should use all the data to train the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee5e9a",
   "metadata": {},
   "source": [
    "# Function train_test_split()\n",
    "\n",
    "* A popular function in the sci-kit learn package for splitting datasets is the \"train test\n",
    "  split\" function.\n",
    "  \n",
    "\t* Split data into random train and test subsets\n",
    "    \n",
    "    \t**from sklearn.model_selection import train_test_split**\n",
    "        \n",
    "        \n",
    "        * x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=0)\n",
    "        \n",
    "        \t\t* x_data = features or independent variables\n",
    "                \n",
    "                * y_data = dataset target = df['price']\n",
    "                \n",
    "                * x_train, y_train = parts of available data as training set\n",
    "                \n",
    "                * x_test, y_test = parts of available data as testing set\n",
    "                \n",
    "                * test_size = percentage of the data for testing (here 30%)\n",
    "                \n",
    "                * random:_state = number generator used for random samplig\n",
    "    \n",
    "    \t* This function randomly splits a dataset into training and testing subsets\n",
    "        \n",
    "        * From the example code snippet, this method is imported from \"sklearn.cross validation.\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c5d9d",
   "metadata": {},
   "source": [
    "# Generalization Performance\n",
    "\n",
    "* Generalization error is a measure of how well our data does at predicting previously unseen\n",
    "  data.\n",
    "\n",
    "* The error we obtain using our testing data is an approximation of this error.\n",
    "\n",
    "* Using a lot of data for training gives us an accurate means of determining how our model\n",
    "  will perform in the real world, but the precision of the performance will be low.\n",
    "  \n",
    "* If we use fewer data points to train the model and more to test the model, the accuracy of\n",
    "  the generalization performance will be less, but the model will have good precision.\n",
    "  \n",
    "\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f059275",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "* One of the most common out-of-sample evaluation metrics is cross-validation.\n",
    "\n",
    "* More effective use of data (each observation is used for bothg training and testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126462ab",
   "metadata": {},
   "source": [
    "# Functions cross_val_score()\n",
    "\n",
    "* The Simplest way to apply cross validation is to call the cross_val_score() function, which performs multiple 'out-of-sample'   evaluations.\n",
    "\n",
    "**from sklearn.model_selection import cross_val_score**\n",
    "\n",
    "* We then use the function cross_val_score().\n",
    "\n",
    "\t\t* scrores = cross_val_scores(lr, x_data, y_data, cv=3)\n",
    "        \n",
    "        \t\t\t* lr = In this example, we initialized a linear regression model or object lr, which we passed to the\n",
    "\t\t\t\t\t  cross_val_score function.\n",
    "                      \n",
    "                      \n",
    "                    * The other parameters are x_data, the predictor variable data, and y_data, the target variable\n",
    "\t\t\t\t\t  data.\n",
    "                      \n",
    "                     \n",
    "                     * cv = 3, which means the data set is split into 3 equal partitions.\n",
    "                     \n",
    "* The function returns an array of scores, one for each partition that was chosen as the\n",
    "  testing set.                    \n",
    "\n",
    "\n",
    "* We can average the result together to estimate out-of-sample R-squared using the mean function\n",
    "  in numpy.\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd091733",
   "metadata": {},
   "source": [
    "# Function cross_val_predict()\n",
    "\n",
    "* The cross_val_score() function returns a score value to tell us the cross-validation\n",
    "  result.\n",
    "  \n",
    "* Has a similar interface to cross_val_score()\n",
    "\n",
    "\n",
    "**What if we want a little more information: what if we want to know the actual predicted\n",
    "  values supplied by our model before the R squared values are calculated?**\n",
    "  \n",
    "  \n",
    "  * To do this, we use the cross_val_predict() function.\n",
    "  \n",
    "  \n",
    "  * The input parameters are exactly the same as the cross_val_score() function, but\n",
    "  \n",
    "    the output is a prediction.\n",
    "    \n",
    "    \n",
    "  **Process**\n",
    "  \n",
    "  \n",
    "  * First, we split the data into three folds; we use two folds for training, the remaining fold for testing.\n",
    "  \n",
    "  \n",
    "  * The model will produce an output, and we will store it in and array.\n",
    "  \n",
    "  \n",
    "  * We will repeat the process using two folds for training, one for testing. \n",
    "  \n",
    "  \n",
    "  * he model produces an output again.\n",
    "  \n",
    "  \n",
    "  * Finally, we use the last two folds for training, then we use the testing data.\n",
    "  \n",
    "  \n",
    "  * This final testing fold produces an output.\n",
    "  \n",
    "  \n",
    "  * These predictions are stored in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc566c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
