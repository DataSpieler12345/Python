{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20c6b151",
   "metadata": {},
   "source": [
    "# Overfitting, Underfitting and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4481beb",
   "metadata": {},
   "source": [
    "##### Model Selection\n",
    "\n",
    "* The goal of model selection is to determine the order of the polynomial to provide the\n",
    "  best estimate of the function y x.\n",
    "  \n",
    "  **y= b0 +b1x**\n",
    "  \n",
    "\n",
    "Consider the following function: we assume the training points come from a polynomial\n",
    "function plus some noise.\n",
    "  \n",
    "  \n",
    "* If we try and fit the function with a linear function, the line is not complex enough to\n",
    "  fit the data.\n",
    "  \n",
    "  * This is called under-fitting, where the model is too simple to fit the data.\n",
    "  \n",
    "  * If we increase the order of the polynomial, the model fits better, but the model is still\n",
    "    not flexible enough and exhibits under-fitting.\n",
    "    \n",
    "    \t* y= b0 + b1x + b2x2\n",
    "  \n",
    "This is an example of the 8th order polynomial used to fit the data; we see the model does\n",
    "well at fitting the data and estimating the function, even at the inflection points.\n",
    "\n",
    "\n",
    " * Increasing it to a 16th order polynomial, the model does extremely well at tracking\n",
    "   the training points, but performs poorly at estimating the function.   \n",
    "   \n",
    "   \n",
    " * This is especially apparent where there is little training data; the estimated function\n",
    "   oscillates not tracking the function.\n",
    "   \n",
    "   \n",
    " * This is called over-fitting, where the model is too flexible and fits the noise rather than the function.\n",
    " \n",
    "\n",
    "Let's look at a plot of the mean square error for the training and testing set for different\n",
    "order polynomials. \n",
    "\n",
    " \n",
    "  * The horizontal axis represents the order of the polynomial; the vertical axis is the mean\n",
    "    square error.\n",
    "    \n",
    "    \n",
    "  * The training error decreases with the order of the polynomial.\n",
    "  \n",
    "  \n",
    "  * The test error is a better means of estimating the error of a polynomial. The error decreases\n",
    "    till the best order of the polynomial is determined, then the error begins to increase.\n",
    "    \n",
    "    \n",
    "  * We select the order that minimizes the test error, in this case, it was 8.\n",
    "  \n",
    "  \n",
    "  * Anything on the left would be considered under-fitting.\n",
    "  \n",
    "  \n",
    "  * Anything on the right is over-fitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc9e8fc",
   "metadata": {},
   "source": [
    "##### We can calculate different R-squared values as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7394ffa8",
   "metadata": {},
   "source": [
    "* First, we create an empty list to store the values.\n",
    "\n",
    "\n",
    "* We create a list containing different polynomial orders.\n",
    "\n",
    "\n",
    "* We then iterate through the list using a loop. We create a polynomial feature object with\n",
    "  the order of the polynomial as a parameter We transform the training and test data into\n",
    "  a polynomial using the fit transform method. We fit the regression model using the transformed\n",
    "  data. We then calculate the R-squared using the\n",
    "  test data and store it in the array.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ffcde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
