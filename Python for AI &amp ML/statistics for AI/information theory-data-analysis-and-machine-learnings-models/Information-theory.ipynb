{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "USKNlN1kNBBt"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axY_JJUSL10z"
   },
   "source": [
    "Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwfsBCynL3fz"
   },
   "source": [
    "Self-Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgrZbQiXL0N9"
   },
   "source": [
    "$I(X)=−log2(p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ybrt_ejXMQBp"
   },
   "source": [
    "\n",
    "$I(A) = −log2(1) = 0$\n",
    "\n",
    "$I(B) = −log2(3/6) = 1$\n",
    "\n",
    "$I(C) = −log2(1/6) = 2.58$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8zxm33yMrpQ"
   },
   "source": [
    "$I(X) = I(0101) = −log2(1/2^4) = 4$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnNjp6BhMQXV",
    "outputId": "172612e3-ddb6-4fc3-ca1f-d571189e4a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "def self_information(p):\n",
    "    return -np.log2(p)\n",
    "\n",
    "print(self_information(1 / 2**4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RU6H-NgNbQt"
   },
   "source": [
    "Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EN90nKYXCt-"
   },
   "source": [
    "$\\mathbb E(X) = \\sum_{i=1}^{k} x_{i} · p_{i}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7x-ZWfJ_eLlO"
   },
   "source": [
    "$H(X) = - \\sum_{i} p_{i} \\log_{2} p_{i}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0z75BpRperY-",
    "outputId": "edf5aae4-c250-4bdb-8cbf-1f2216c9a235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6854752972273346\n"
     ]
    }
   ],
   "source": [
    "# np.nansum return the sum of NaNs. Treats them as zeros.\n",
    "\n",
    "def entropy(p):\n",
    "    out = np.nansum(-p * np.log2(p))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "print(entropy(np.array([0.1, 0.5, 0.1, 0.3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LlmkYuBfEc5"
   },
   "source": [
    "Joint Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uS75xtXfOrp"
   },
   "source": [
    "$H(X, Y) = - \\sum_{x} \\sum_{y} p_{X, Y}(x, y) \\log_{2} p_{X, Y}(x, y)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13gb1nVvfP3V",
    "outputId": "5f2f83db-fc24-424b-ec3c-861439a997dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0558948969327187\n"
     ]
    }
   ],
   "source": [
    "def joint_entropy(p_xy):\n",
    "    out = np.nansum(-p_xy * np.log2(p_xy))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "a = [0.1, 0.5, 0.8]\n",
    "b = [0.1, 0.3, 0.02]\n",
    "print(joint_entropy(np.array([a, b])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oIj5Ckbf1oU",
    "outputId": "a138fa5f-0257-4fb4-901b-4d782822ca3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0558948969327187"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(np.array(a)) + entropy(np.array(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlCmSkvFgUg3"
   },
   "source": [
    "$H(Y \\mid X) = - \\sum_{x} \\sum_{y} p(x, y) \\log_{2} p(y \\mid x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpWYEyJygvd7"
   },
   "source": [
    "$H(Y \\mid X) = H(X, Y) - H(X)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6UObodbygCGc",
    "outputId": "3c3677b7-8b1e-4ca1-bfcd-40368c1257f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863547202339972\n"
     ]
    }
   ],
   "source": [
    "def conditional_entropy(p_xy, p_x):\n",
    "    p_y_given_x = p_xy / p_x\n",
    "    out = np.nansum(-p_xy * np.log2(p_y_given_x))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "print(conditional_entropy(np.array([[0.1, 0.5], [0.2, 0.3]]), np.array([0.2, 0.8])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3J2YOW6j8No"
   },
   "source": [
    "Mutual information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_hHTF8fk0rR"
   },
   "source": [
    "$I(X, Y) = H(X, Y) - H(Y \\mid X) − H(X \\mid Y)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mhJYRajhCbb",
    "outputId": "4530c272-a163-424c-ebf9-a74d7e9a1b86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7194602975157967\n"
     ]
    }
   ],
   "source": [
    "def mutual_information(p_xy, p_x, p_y):\n",
    "    p = p_xy / (p_x * p_y)\n",
    "    out = np.nansum(p_xy * np.log2(p))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "print(mutual_information(np.array([[0.1, 0.5], [0.1, 0.3]]),\n",
    "                        np.array([0.2, 0.8]),\n",
    "                        np.array([[0.75, 0.25]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dntwPAoooQm"
   },
   "source": [
    "Kullback–Leibler Divergence - Relative Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOZFidlKoilJ"
   },
   "source": [
    "$D_{\\mathrm{KL}}(P\\|Q) = E_{x \\sim P} \\left[ \\log \\frac{p(x)}{q(x)} \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icqyVt8xlTr9",
    "outputId": "0485327c-f44e-4018-b118-d344170a5055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.65252351910203\n"
     ]
    }
   ],
   "source": [
    "def kl_divergence(p, q):\n",
    "     kl = p * np.log2(p / q)\n",
    "     out = np.nansum(p * np.log2(p / q))\n",
    "\n",
    "     return np.abs(out)\n",
    "\n",
    "p = np.random.normal(100, 1, size=1000)\n",
    "q = np.random.normal(100, 1, size=1000)\n",
    "\n",
    "print(kl_divergence(p, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZTff4qlqOKE"
   },
   "source": [
    "Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vArdZB-uZFZ"
   },
   "source": [
    "$\\mathrm{CE} (P, Q) = H(P) + D_{\\mathrm{KL}}(P\\|Q)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdgvAhqoudWW"
   },
   "source": [
    "$\\mathrm{CE}(\\mathbf{y}, \\hat{\\mathbf{y}}) = - \\sum_{i=1}^n \\sum_{j=1}^k y_{ij} \\log_{2}{p_{\\theta} (y_{ij}  \\mid  \\mathbf{x}_i)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZz7hKx-qPAr",
    "outputId": "45fa625d-1698-4b26-faaf-461d386c19f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9485599924429406\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    ce = - np.log(y_hat[range(len(y_hat)), y])\n",
    "\n",
    "    return ce.mean()\n",
    "\n",
    "\n",
    "labels = np.array([0, 2])\n",
    "preds = np.array([[0.3, 0.6, 0.1], [0.2, 0.3, 0.5]])\n",
    "\n",
    "print(cross_entropy(preds, labels))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Information theory.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
